{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: 'Image Analysis'\n",
    "## First Year Project  \n",
    "### ITU, Spring 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all the code developed to explore, wrangle and analyse the raw data sets for our project, 'Image Analysis'.\n",
    "\n",
    "Contributors:  \n",
    "- Andy Bao Nguyen (anbn)\n",
    "- Florian Micliuc (flmi)\n",
    "- Mattias Wohlert \n",
    "- Sofia Elena Terenziani (sote)\n",
    "\n",
    "Created: 06-04-2021 \n",
    "\n",
    "Last modified: 22-04-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "import timeit\n",
    "import missingno as msno\n",
    "import requests\n",
    "import shutil\n",
    "from skimage import morphology\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats.stats import mode\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from skimage.color import rgb2hsv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on an average laptop, it takes quite some time, it's a zip file of 6gb worth of pictures\n",
    "url = 'https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Data.zip'\n",
    "r = requests.get(url , allow_redirects = True)\n",
    "open('ISIC-2017_Training_Data.zip', 'wb').write(r.content);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://isic-challenge-data.s3.amazonaws.com/2017/ISIC-2017_Training_Part1_GroundTruth.zip'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('ISIC-2017_Validation_Part1_GroundTruth.zip', 'wb').write(r.content);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to unzip the two files downloaded previously and then run the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_image_folder = 'ISIC-2017_Training_Data'\n",
    "extra_ground_truth = 'ISIC-2017_Training_Part3_GroundTruth.csv' #can be found in the .zip file uploaded on learnit\n",
    "extra_segmentation = 'ISIC-2017_Validation_Part1_GroundTruth/ISIC-2017_Training_Part1_GroundTruth'\n",
    "\n",
    "extra_image_files = os.listdir(extra_image_folder)\n",
    "seg = os.listdir(extra_segmentation)\n",
    "gt = pd.read_csv(extra_ground_truth)\n",
    "\n",
    "gt = gt.set_index('image_id')\n",
    "\n",
    "keratosis_images = gt.index[gt['seborrheic_keratosis'] == 1.0].tolist()\n",
    "\n",
    "\n",
    "directory1 = 'extra_keratosis'\n",
    "os.mkdir(directory1)\n",
    "for file_name in keratosis_images:\n",
    "    full_file_name = os.path.join(extra_image_folder,file_name + '.jpg')\n",
    "    if os.path.isfile(full_file_name):\n",
    "        shutil.copy(full_file_name,'extra_keratosis')\n",
    "\n",
    "directory = \"extra_segmentation\"\n",
    "os.mkdir(directory)\n",
    "for file_name in keratosis_images:\n",
    "    full_file_name = os.path.join(extra_segmentation, file_name +'_segmentation'+'.png')\n",
    "    if os.path.isfile(full_file_name):\n",
    "        shutil.copy(full_file_name, 'extra_segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_values(file, string):\n",
    "        if file.isnull().values.any():\n",
    "            print('There are null values in {} dataset'.format(string))\n",
    "        else:\n",
    "            print('There are no null values in {} dataset'.format(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_checker_values(dataset,value):\n",
    "    SA = dataset.copy()\n",
    "    SA.replace(value, np.nan, inplace=True)\n",
    "    missingdata_df = SA.columns[SA.isnull().any()].tolist()\n",
    "    msno.matrix(SA);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detect(img):\n",
    "    \n",
    "    \n",
    "    test_image = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    image_unblur = cv2.resize(test_image, (500, 400))\n",
    "    \n",
    "    imageB = cv2.GaussianBlur(image_unblur, (5,5), 0) #Bias for if images are considered blurry\n",
    "\n",
    "    #Laplacian.var() works in such a way that it checks for defined edges, how many clear edges/lines is present\n",
    "    img_var = cv2.Laplacian(image_unblur, cv2.CV_64F, ksize=11).var()\n",
    "    img_var_blur = cv2.Laplacian(imageB, cv2.CV_64F, ksize=11).var()\n",
    "\n",
    "    if img_var < 100000000000:\n",
    "        print(img_var, \"variance value is less than 100 milliard, the image is considered blurry\")\n",
    "    else:\n",
    "        print(img_var, \"variance value is above 100 milliard, image is not considered blurry\")\n",
    "\n",
    "    #Prints the variance value of the blur filter we make in the code, not needed\n",
    "    #print(img_var_blur, \"variance value of an image with gaussian blur filter on\")\n",
    "\n",
    "    \n",
    "    #cv2.imshow(\"Original image no blur\", image_unblur)\n",
    "    #cv2.imshow(\"Blur filter\", imageB)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colour analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image):\n",
    "    y_nonzero, x_nonzero, _ = np.nonzero(image)\n",
    "    return image[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB2HEX(color):\n",
    "     return \"#{:02x}{:02x}{:02x}\".format(int(color[0]), int(color[1]), int(color[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_reader(img,mk):\n",
    "    im = plt.imread(img)\n",
    "    #mask is the gray segmentation mask\n",
    "    mask = plt.imread(mk)\n",
    "    #putting the color over the mask\n",
    "    im1 = im.copy()\n",
    "    im1[mask==0] = 0 #again python dark magic\n",
    "    #now for better performance we have to crop the image to it's extremities by calling the crop function\n",
    "    img2 = crop(im1)\n",
    "    #we have to get the coordinates of every pixel in the image so\n",
    "    xy_coords = np.flip(np.column_stack(np.where(img2 >= 0)), axis=1)\n",
    "    #if we print xy_coords they will appear three times because every pixel has three colour coordinates, namely RGB,thus\n",
    "    #I have to delete the first column(which is 0,1,2) and the duplicates\n",
    "    a_del = np.delete(xy_coords, 0, 1)\n",
    "    a_del = a_del[::3][:, [0, 1]] #python dark magic\n",
    "    #now we get all the rgb colours from every pixel in our picture\n",
    "    image = Image.fromarray(img2)\n",
    "    rgb_image = image.convert('RGB')\n",
    "    rgb1 = [rgb_image.getpixel((int(i[0]),int(i[1]))) for i in a_del]\n",
    "    #now to reduce it as much as we can we turn it to hexcodes so we don't have tuples of 3 values and we eliminate duplicates\n",
    "    dd = [RGB2HEX(i) for i in rgb1]\n",
    "    ss = list(set(dd)) #ye,I know\n",
    "    #now just a nice thing, to count how many colours appear in our picture, first one is useless since it will always be black\n",
    "    counter_colours =  Counter(dd)\n",
    "    #popping the black color\n",
    "    counter_colours.pop('#000000')\n",
    "    return counter_colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv(img,seg):    \n",
    "    im = plt.imread(img)\n",
    "    mask = plt.imread(seg)\n",
    "    im1 = im.copy()\n",
    "    im1[mask==0] = 0\n",
    "    new_arr_no_0 = im1[np.where(im1!=0)]\n",
    "    img2 = crop(im1)\n",
    "    image_copy = img2.copy()\n",
    "    non_black_pixels_mask = np.any(img2 != [0, 0, 0], axis=-1)  \n",
    "    no_black = image_copy[non_black_pixels_mask]\n",
    "    hsv_image = rgb2hsv(no_black)\n",
    "    min_max = [np.amax(hsv_image[:,1]) - np.amin(hsv_image[:,1])]\n",
    "    return min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value(img,seg):\n",
    "    im = plt.imread(img)\n",
    "    mask = plt.imread(seg)\n",
    "    im1 = im.copy()\n",
    "    im1[mask==0] = 0\n",
    "    new_arr_no_0 = im1[np.where(im1!=0)]\n",
    "    img2 = crop(im1)\n",
    "    image_copy = img2.copy()\n",
    "    non_black_pixels_mask = np.any(img2 != [0, 0, 0], axis=-1)  \n",
    "    no_black = image_copy[non_black_pixels_mask]\n",
    "    hsv_image = rgb2hsv(no_black)\n",
    "    min_max = [np.amax(hsv_image[:,2]) - np.amin(hsv_image[:,2])]\n",
    "    return min_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asymmetry functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetry_level(im): \n",
    "    #Read image\n",
    "    im = plt.imread(im)\n",
    "    \n",
    "    #Crop the picture\n",
    "    #Center of the shape is the center of the image\n",
    "    #The borders of the shape are the borders of the image\n",
    "    y_nonzero, x_nonzero = np.nonzero(im)\n",
    "    im = im[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)]\n",
    "    \n",
    "    #Cut the image in halves \n",
    "    #Find the point of cutoff\n",
    "    height, width = im.shape\n",
    "    width_cutoff = width // 2\n",
    "    height_cutoff = height // 2\n",
    "    \n",
    "    #Cut the image vertically and horizontally in two \n",
    "    imVertical1 = im[:, :width_cutoff]\n",
    "    imVertical2 = im[:, width_cutoff:]\n",
    "    imHorizontal1 = im[:height_cutoff, :]\n",
    "    imHorizontal2 = im[height_cutoff:, :]\n",
    "    \n",
    "    #Flip image \n",
    "    #Interting one of the images both vertically and horizontally   \n",
    "    indexerVertical = [slice(None)] * imVertical2.ndim\n",
    "    indexerHorizontal = [slice(None)] * imHorizontal2.ndim\n",
    "    indexerVertical[1] = slice(None, None, -1)\n",
    "    indexerHorizontal[0] = slice(None, None, -1) \n",
    "    imVertical2 = imVertical2[tuple(indexerVertical)]\n",
    "    imHorizontal2 = imHorizontal2[tuple(indexerHorizontal)]\n",
    "\n",
    "    #Cut the biggest image, if the images don't have the same shape \n",
    "    #This can happen if the shape of the original shape was an odd number \n",
    "    imVertical2 = imVertical2[0:imVertical1.shape[0], 0:imVertical1.shape[1]]\n",
    "    imHorizontal2 = imHorizontal2[0:imHorizontal1.shape[0], 0:imHorizontal1.shape[1]]\n",
    "\n",
    "    img_bwxVertical = cv2.bitwise_xor(imVertical1,imVertical2)\n",
    "    img_bwxHorizontal = cv2.bitwise_xor(imHorizontal1,imHorizontal2)\n",
    "    \n",
    "    areaVertical = np.sum(img_bwxVertical == 1)\n",
    "    areaHorizontal = np.sum(img_bwxHorizontal == 1)\n",
    "    areaMean = (areaVertical + areaHorizontal) // 2\n",
    "    \n",
    "    #The asymmetry level (AS) is calculated as a percentage of the non-zero pixels in the overlapped image over the lesion area \n",
    "    return (areaMean / np.sum(im == 1)) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_knn_prediction(k,train,classes,test):\n",
    "    neigh = KNeighborsClassifier(n_neighbors = k)\n",
    "    neigh.fit(train,classes.ravel())\n",
    "    clas_pred = neigh.predict(test)\n",
    "    return clas_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(k,train,classes,test,classes_test):\n",
    "    performance = []\n",
    "    perform1 =[]\n",
    "    for i in range(1,k):\n",
    "        a = make_knn_prediction(i,train,classes,test)\n",
    "        performance.append(a)\n",
    "        for j in performance:\n",
    "            b = accuracy_score(classes_test,j)\n",
    "        perform1.append(b)\n",
    "    fig, axes = plt.subplots()\n",
    "    axes.plot(perform1)\n",
    "    plt.title(\"Classification Accuracy of KNN for Different Values of k\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    plt.xlabel(\"Value of k\");\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "    return np.mean(perform1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading description pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '../data/raw/example_image/'\n",
    "segmentation_folder = '../data/raw/example_segmentation/'\n",
    "\n",
    "extra_image_folder = '../data/raw/extra_keratosis'\n",
    "extra_segmentation_folder = '../data/raw/extra_segmentation'\n",
    "\n",
    "\n",
    "extra_ground_truth = '../data/raw/ISIC-2017_Training_Part3_GroundTruth.csv'\n",
    "ground_truth = '../data/raw/example_ground_truth.csv'\n",
    "features = '../data/features/features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = os.listdir(image_folder)\n",
    "segmentation_files = os.listdir(segmentation_folder)\n",
    "\n",
    "extra_image_files = os.listdir(extra_image_folder)\n",
    "extra_segmentation_files = os.listdir(extra_segmentation_folder)\n",
    "\n",
    "extra_gt = pd.read_csv(extra_ground_truth)\n",
    "ground_truth = pd.read_csv(ground_truth)\n",
    "features = pd.read_csv(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 - Data checking and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV files sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_null_values(ground_truth,'ground_truth')\n",
    "check_null_values(features,'features')\n",
    "check_null_values(extra_gt,'extra_ground_truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_checker_values(ground_truth,-1)\n",
    "dataset_checker_values(features,-1)\n",
    "dataset_checker_values(extra_gt,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no gaps in the plots, thus the value -1 (missing data) does not occur in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True in list(ground_truth.duplicated()):\n",
    "    print(\"Duplicate rows\")\n",
    "else: \n",
    "    print(\"No duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True in list(features.duplicated()):\n",
    "    print(\"Duplicate rows\")\n",
    "else:\n",
    "    print(\"No duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True in list(extra_gt.duplicated()):\n",
    "    print('Duplicate rows')\n",
    "else:\n",
    "    print('No duplicate rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ground_truth.set_index('image_id')\n",
    "features = features.set_index('id')\n",
    "extra_gt = extra_gt.set_index('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_images_paths = []\n",
    "segmentation = []\n",
    "\n",
    "# getting the image_paths\n",
    "for i in image_files[1:]:\n",
    "    image_path= os.path.join(image_folder,i)\n",
    "    if not i.endswith('superpixels.png'):\n",
    "        color_images_paths.append(image_path)\n",
    "for i in segmentation_files:\n",
    "    image_path1 = os.path.join(segmentation_folder,i)\n",
    "    segmentation.append(image_path1)\n",
    "\n",
    "both_images = list(zip(color_images_paths,segmentation))\n",
    "\n",
    "#splitting the images\n",
    "keratosis_images = ground_truth.index[ground_truth['seborrheic_keratosis'] == 1.0].tolist()\n",
    "melanoma_images = ground_truth.index[ground_truth['melanoma'] == 1.0].tolist()\n",
    "healthy_images = ground_truth[(ground_truth['seborrheic_keratosis'] == 0.0) & (ground_truth['melanoma'] == 0.0)]\n",
    "#print(healthy_images.index.tolist) - to get only the healthy images in a list hence the healthy_images is a df\n",
    "\n",
    "keratosis = [os.path.join(image_folder,i + '.jpg') for i in keratosis_images] #positive keratosis colour_images path\n",
    "melanoma = [os.path.join(image_folder,i + '.jpg') for i in melanoma_images] #positive melanoma colour_images path\n",
    "healthy = [os.path.join(image_folder,i + '.jpg') for i in healthy_images.index.tolist()] #healthy colour_images path\n",
    "\n",
    "k_segmentation = [os.path.join(segmentation_folder,i + '_segmentation.png') for i in keratosis_images] #positive keratosis segmentation path\n",
    "m_segmentation = [os.path.join(segmentation_folder,i + '_segmentation.png') for i in melanoma_images] #positive melanoma segmentation path\n",
    "h_segmentation = [os.path.join(segmentation_folder,i + '_segmentation.png') for i in healthy_images.index.tolist()]#healthy segmentation path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_keratosis = list(zip(keratosis,k_segmentation))\n",
    "final_melanoma = list(zip(melanoma,m_segmentation))\n",
    "final_healthy = list(zip(healthy,h_segmentation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Data - provided from ISIC 2017 challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see the code used for filtering the extra dataset. To simplify working with a large dataset (2000 images) and github, we worked locally by extracting only the keratosis and keratosis_segmentation images and copying them to two other distinct folders and the pushing them into the github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_keratosis = [os.path.join(extra_image_folder,i) for i in extra_image_files]\n",
    "extra_segmentation = [os.path.join(extra_segmentation_folder,i) for i in extra_segmentation_files ]\n",
    "final_extra = list(zip(extra_keratosis,extra_segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keratosis_all = final_keratosis + final_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_k_all = k_segmentation + extra_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bluriness detection for every image in the extra_keratosis dataset (200 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#check = [edge_detect(i) for i in extra_keratosis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check = [edge_detect(i) for i in keratosis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_list = []\n",
    "for i in extra_keratosis:\n",
    "    a = plt.imread(i)\n",
    "    shape_list.append(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_list_2 = []\n",
    "for i in keratosis:\n",
    "    b = plt.imread(i)\n",
    "    shape_list_2.append(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_df_extra = pd.DataFrame(shape_list,columns = ['Height','Width','Channels'])\n",
    "shape_df = pd.DataFrame(shape_list_2,columns = ['Height','Width','Channels'])\n",
    "#the (,,3) represent wether or not it is a coloured picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bluriness detection and the graphic resolution both are powerful tools into disqualifying images. The bluriness detection is something which we still need to investigate if it is a reliable tool to use for disqualification. On the other hand, graphic resolution could tell us about how visible are the small details (the bigger the resolution, the more pixels there are) and it is very reliable to disqualify images for that.  \n",
    "\n",
    "Ultimately, our group decided to not disqualify any images from the extra dataset or the original dataset due to the reasoning that after careful investigation we decided that all images fit our requested parameters, thus no extra filtering was needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Colour Analysis - Step by step example of the colour_reader function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the coloured and the segmentation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread(keratosis[1])\n",
    "mask = plt.imread(k_segmentation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic knowledge about the lession such as area and perimeter (not absolutely necessary for colour analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = np.sum(mask)\n",
    "struct_el = morphology.disk(1)\n",
    "mask_eroded = morphology.binary_erosion(mask, struct_el)\n",
    "image_perimeter = mask - mask_eroded\n",
    "perimeter = np.sum(image_perimeter)\n",
    "plt.imshow(image_perimeter,cmap = 'cool') # really small but visible with cool cmap\n",
    "#print(' The area is -> ',area,'\\\\n','The perimeter is -> ',perimeter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the lession and displaying it over the segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = im.copy()\n",
    "im1[mask==0] = 0\n",
    "new_arr_no_0 = im1[np.where(im1!=0)]\n",
    "#cropping the image for better performance\n",
    "im1 = crop(im1)\n",
    "plt.imshow(im1) #not best crop but manageable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting every pixel's coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_coords = np.flip(np.column_stack(np.where(im1 >= 0)), axis=1)\n",
    "a_del = np.delete(xy_coords, 0, 1)\n",
    "a_del = a_del[::3][:, [0, 1]] #python dark magic and true coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting every pixel's RGB values and converting them to HEX codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.fromarray(im1)\n",
    "rgb_image = image.convert('RGB')\n",
    "rgb1 = [rgb_image.getpixel((int(i[0]),int(i[1]))) for i in a_del] #getting the RGB value for every pixel in the lession\n",
    "hex_codes = [RGB2HEX(i) for i in rgb1] #converting all to hex\n",
    "counted_colours = Counter(hex_codes) #counting them\n",
    "counted_colours.pop('#000000') #popping the blackest black colour\n",
    "print(len(rgb1)) #3,379,770 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(counted_colours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversion of the RGB values to hex codes is due to the fact RGB values come in tuples of three (R,G,B), therefore, for a better performance we turn them to HEX codes ( which are basically #RGB values ) and then we count their appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# really long running time, ~ 1h\n",
    "final_k = [colour_reader(i[0],i[1]) for i in Keratosis_all]\n",
    "final_h = [colour_reader(i[0],i[1]) for i in final_healthy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_len = [len(i) for i in final_k]\n",
    "h_len = [len(i) for i in final_h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing k_len and h_len for the prediction algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k_len - is the number of colours found in every picture (in every pixel of that picture) for the keratosis dataset  \n",
    "h_len - is the number of colours found in every picture (in every pixel of that picture) for the healthy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Colour Analysis - Step by step example explaining the hsv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_copy = im1.copy()\n",
    "non_black_pixels_mask = np.any(im1 != [0, 0, 0], axis=-1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the first image and then creating a mask without the black borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_pic = rgb2hsv(image_copy[non_black_pixels_mask])\n",
    "maximum = np.max(hsv_pic[:,1])\n",
    "minimum = np.min(hsv_pic[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the image from RGB values to HSV values to get the saturation and getting the difference between brightest and darkest spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_hsv = [hsv(i[0],i[1]) for i in Keratosis_all]\n",
    "h_hsv = [hsv(i[0],i[1]) for i in final_healthy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing k_hsv and h_hsv for the predicition algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k_hsv - is the difference between the brightest and darkest points from every picture in the keratosis dataset  \n",
    "h_hsv - is the difference between the brightest and darkest points from every picture in the healthy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Symmetry analysis - Step by step example explaining the asymmetry level function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_sym = plt.imread(k_segmentation[1])\n",
    "y_nonzero, x_nonzero = np.nonzero(im_sym)\n",
    "im_sym = im_sym[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop the picture  \n",
    "Center of the shape is the center of the image  \n",
    "The borders of the shape are the borders of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = im_sym.shape\n",
    "width_cutoff = width // 2\n",
    "height_cutoff = height // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut the image in halves   \n",
    "Find the point of cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imVertical1 = im_sym[:, :width_cutoff]\n",
    "imVertical2 = im_sym[:, width_cutoff:]\n",
    "imHorizontal1 = im_sym[:height_cutoff, :]\n",
    "imHorizontal2 = im_sym[height_cutoff:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut the image vertically and horizontally in two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexerVertical = [slice(None)] * imVertical2.ndim\n",
    "indexerHorizontal = [slice(None)] * imHorizontal2.ndim\n",
    "indexerVertical[1] = slice(None, None, -1)\n",
    "indexerHorizontal[0] = slice(None, None, -1) \n",
    "imVertical2 = imVertical2[tuple(indexerVertical)]\n",
    "imHorizontal2 = imHorizontal2[tuple(indexerHorizontal)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip image  \n",
    "Interting one of the images both vertically and horizontally  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imVertical2 = imVertical2[0:imVertical1.shape[0], 0:imVertical1.shape[1]]\n",
    "imHorizontal2 = imHorizontal2[0:imHorizontal1.shape[0], 0:imHorizontal1.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut the biggest image, if the images don't have the same shape   \n",
    "This can happen if the shape of the original shape was an odd number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_bwxVertical = cv2.bitwise_xor(imVertical1,imVertical2)\n",
    "img_bwxHorizontal = cv2.bitwise_xor(imHorizontal1,imHorizontal2)\n",
    "fig, axes = plt.subplots(1, 2, figsize =(10,10))\n",
    "axes[0].imshow(img_bwxVertical, cmap='gray')\n",
    "axes[1].imshow(img_bwxHorizontal, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areaVertical = np.sum(img_bwxVertical == 1)\n",
    "areaHorizontal = np.sum(img_bwxHorizontal == 1)\n",
    "areaMean = (areaVertical + areaHorizontal) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(areaMean / np.sum(im_sym == 1) *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The asymmetry level (AS) is calculated as a percentage of the non-zero pixels in the overlapped image over the lesion area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_sym = [asymmetry_level(i) for i in segm_k_all]\n",
    "h_sym = [asymmetry_level(i) for i in h_segmentation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing k_sym and h_sym for the prediction algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k_sym - is the asymmetry level of every segmentation picture in the keratosis segmentation dataset  \n",
    "h_sym - is the asymmetry level of every segmentation picture in the healthy segmentation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Diagnosis prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_k = np.array([1 for i in range(len(Keratosis_all))])\n",
    "clas_h = np.array([0 for i in range(len(healthy))])\n",
    "clas = np.array([y for x in [clas_k, clas_h] for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Color variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = np.array(k_len + h_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_train,feed_test,clas_train,clas_test = train_test_split(feed,clas,test_size = 0.6,random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_train= feed_train.reshape(-1, 1)\n",
    "clas_train= clas_train.reshape(-1, 1)\n",
    "feed_test = feed_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_knn_prediction(7,feed_train,clas_train,feed_test))\n",
    "print(clas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test(120,feed_train,clas_train,feed_test,clas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed2 = np.array([y for x in [k_hsv, h_hsv] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed2_train,feed2_test,clas_train,clas_test = train_test_split(feed2,clas,test_size = 0.6,random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed2_train= feed2_train.reshape(-1, 1)\n",
    "clas_train= clas_train.reshape(-1, 1)\n",
    "feed2_test = feed2_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_knn_prediction(7,feed2_train,clas_train,feed2_test))\n",
    "print(clas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test(120,feed2_train,clas_train,feed2_test,clas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed3 = np.array([y for x in [k_sym, h_sym] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed3_train,feed3_test,clas_train,clas_test = train_test_split(feed3,clas,test_size = 0.6,random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed3_train= feed3_train.reshape(-1, 1)\n",
    "clas_train= clas_train.reshape(-1, 1)\n",
    "feed3_test = feed3_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_knn_prediction(7,feed3_train,clas_train,feed3_test))\n",
    "print(clas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test(120,feed3_train,clas_train,feed3_test,clas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Open question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our open question is in regards with the saturation ( which in our case measures the difference between the most saturated and the least saturated colours in the lession thus showing us the saturation variation) and the lightness value ( which in our case measures the diffrence between the brightest and the darkest colours in the lession thus showing us the lightness variation ). Therefore the question is which one would be more fitted to be a good feature to predict the diagnosis of a skin lession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_value = [value(i[0],i[1]) for i in Keratosis_all]\n",
    "h_value = [value(i[0],i[1]) for i in final_healthy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the difference between the brightest and darkest colour in all 242 keratosis pictures and the 78 healthy pictures and then feed them to the KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed4 = np.array([y for x in [k_value,h_value] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed4_train,feed4_test,clas_train,clas_test = train_test_split(feed4,clas,test_size = 0.6,random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed4_train= feed4_train.reshape(-1, 1)\n",
    "clas_train= clas_train.reshape(-1, 1)\n",
    "feed4_test = feed4_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_knn_prediction(7,feed4_train,clas_train,feed4_test))\n",
    "print(clas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_test(120,feed4_train,clas_train,feed4_test,clas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we comput the accuracy score for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test(120,feed4_train,clas_train,feed4_test,clas_test)\n",
    "accuracy_test(120,feed2_train,clas_train,feed2_test,clas_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare the accuracy scores of both models and both seem to stabilize at ~74% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_value = average_precision_score(clas_test,feed4_test)\n",
    "average_precision_saturation = average_precision_score(clas_test,feed2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we compute average_precision value for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The precision for the lightness value of the colour is',average_precision_value)\n",
    "print('The precision for the difference of the saturation of the colour',average_precision_saturation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this analysis we can conclude (if there are no flaws in our implementation) that the lightness variation is slighty more precise than the saturation variation. Though this conclusion raises other questions:  \n",
    "- Is the ~0.06 difference significant? \n",
    "- Can it affect the results of the model in any way?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
