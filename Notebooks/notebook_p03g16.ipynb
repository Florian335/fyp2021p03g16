{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: 'Image Analysis'\n",
    "## First Year Project  \n",
    "### ITU, Spring 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all the code developed to explore, wrangle and analyse the raw data sets for our project, 'Image Analysis'.\n",
    "\n",
    "Contributors:  \n",
    "- Andy Bao Nguyen (anbn)\n",
    "- Florian Micliuc (flmi)\n",
    "- Mattias Wohlert \n",
    "- Sofia Elena Terenziani (sote)\n",
    "\n",
    "Created: 06-04-2021 \n",
    "\n",
    "Last modified:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "import timeit\n",
    "import missingno as msno\n",
    "from skimage import morphology\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats.stats import mode\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from skimage.color import rgb2hsv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_values(file, string):\n",
    "        if file.isnull().values.any():\n",
    "            print('There are null values in {} dataset'.format(string))\n",
    "        else:\n",
    "            print('There are no null values in {} dataset'.format(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_checker_values(dataset,value):\n",
    "    SA = dataset.copy()\n",
    "    SA.replace(value, np.nan, inplace=True)\n",
    "    missingdata_df = SA.columns[SA.isnull().any()].tolist()\n",
    "    msno.matrix(SA);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colour analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image):\n",
    "    y_nonzero, x_nonzero, _ = np.nonzero(image)\n",
    "    return image[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB2HEX(color):\n",
    "     return \"#{:02x}{:02x}{:02x}\".format(int(color[0]), int(color[1]), int(color[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_reader(img,mk):\n",
    "    im = plt.imread(img)\n",
    "    #mask is the gray segmentation mask\n",
    "    mask = plt.imread(mk)\n",
    "    #putting the color over the mask\n",
    "    im1 = im.copy()\n",
    "    im1[mask==0] = 0 #again python dark magic\n",
    "    #now for better performance we have to crop the image to it's extremities by calling the crop function\n",
    "    img2 = crop(im1)\n",
    "    #we have to get the coordinates of every pixel in the image so\n",
    "    xy_coords = np.flip(np.column_stack(np.where(img2 >= 0)), axis=1)\n",
    "    #if we print xy_coords they will appear three times because every pixel has three colour coordinates, namely RGB,thus\n",
    "    #I have to delete the first column(which is 0,1,2) and the duplicates\n",
    "    a_del = np.delete(xy_coords, 0, 1)\n",
    "    a_del = a_del[::3][:, [0, 1]] #python dark magic\n",
    "    #now we get all the rgb colours from every pixel in our picture\n",
    "    image = Image.fromarray(img2)\n",
    "    rgb_image = image.convert('RGB')\n",
    "    rgb1 = [rgb_image.getpixel((int(i[0]),int(i[1]))) for i in a_del]\n",
    "    #now to reduce it as much as we can we turn it to hexcodes so we don't have tuples of 3 values and we eliminate duplicates\n",
    "    dd = [RGB2HEX(i) for i in rgb1]\n",
    "    ss = list(set(dd)) #ye,I know\n",
    "    #now just a nice thing, to count how many colours appear in our picture, first one is useless since it will always be black\n",
    "    counter_colours =  Counter(dd)\n",
    "    #popping the black color\n",
    "    counter_colours.pop('#000000')\n",
    "    return counter_colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv(img,seg):\n",
    "    im = plt.imread(img)\n",
    "    mask = plt.imread(seg)\n",
    "    im1 = im.copy()\n",
    "    im1[mask==0] = 0\n",
    "    new_arr_no_0 = im1[np.where(im1!=0)]\n",
    "    img2 = crop(im1)\n",
    "    image_copy = img2.copy()\n",
    "    non_black_pixels_mask = np.any(img2 != [0, 0, 0], axis=-1)  \n",
    "    no_black = image_copy[non_black_pixels_mask]\n",
    "    hsv_image = rgb2hsv(no_black)\n",
    "    min_max = [np.amax(hsv_image[:,1]) - np.amin(hsv_image[:,1])]\n",
    "    return min_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asymmetry functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetry_level(im): \n",
    "    #Read image\n",
    "    im = plt.imread(im)\n",
    "    \n",
    "    #Crop the picture\n",
    "    #Center of the shape is the center of the image\n",
    "    #The borders of the shape are the borders of the image\n",
    "    y_nonzero, x_nonzero = np.nonzero(im)\n",
    "    im = im[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)]\n",
    "    \n",
    "    #Cut the image in halves \n",
    "    #Find the point of cutoff\n",
    "    height, width = im.shape\n",
    "    width_cutoff = width // 2\n",
    "    height_cutoff = height // 2\n",
    "    \n",
    "    #Cut the image vertically and horizontally in two \n",
    "    imVertical1 = im[:, :width_cutoff]\n",
    "    imVertical2 = im[:, width_cutoff:]\n",
    "    imHorizontal1 = im[:height_cutoff, :]\n",
    "    imHorizontal2 = im[height_cutoff:, :]\n",
    "    \n",
    "    #Flip image \n",
    "    #Interting one of the images both vertically and horizontally   \n",
    "    indexerVertical = [slice(None)] * imVertical2.ndim\n",
    "    indexerHorizontal = [slice(None)] * imHorizontal2.ndim\n",
    "    indexerVertical[1] = slice(None, None, -1)\n",
    "    indexerHorizontal[0] = slice(None, None, -1) \n",
    "    imVertical2 = imVertical2[tuple(indexerVertical)]\n",
    "    imHorizontal2 = imHorizontal2[tuple(indexerHorizontal)]\n",
    "\n",
    "    #Cut the biggest image, if the images don't have the same shape \n",
    "    #This can happen if the shape of the original shape was an odd number \n",
    "    imVertical2 = imVertical2[0:imVertical1.shape[0], 0:imVertical1.shape[1]]\n",
    "    imHorizontal2 = imHorizontal2[0:imHorizontal1.shape[0], 0:imHorizontal1.shape[1]]\n",
    "\n",
    "    img_bwxVertical = cv2.bitwise_xor(imVertical1,imVertical2)\n",
    "    img_bwxHorizontal = cv2.bitwise_xor(imHorizontal1,imHorizontal2)\n",
    "    \n",
    "    areaVertical = np.sum(img_bwxVertical == 1)\n",
    "    areaHorizontal = np.sum(img_bwxHorizontal == 1)\n",
    "    areaMean = (areaVertical + areaHorizontal) // 2\n",
    "    \n",
    "    #The asymmetry level (AS) is calculated as a percentage of the non-zero pixels in the overlapped image over the lesion area \n",
    "    return (areaMean / np.sum(im == 1)) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_knn_prediction(k,train,classes,test):\n",
    "    neigh = KNeighborsClassifier(n_neighbors = k)\n",
    "    neigh.fit(train,classes.ravel())\n",
    "    clas_pred = neigh.predict(test)\n",
    "    return clas_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(k,train,classes,test,classes_test):\n",
    "    performance = []\n",
    "    perform1 =[]\n",
    "    for i in range(1,k):\n",
    "        a = make_knn_prediction(i,train,classes,test)\n",
    "        performance.append(a)\n",
    "        for j in performance:\n",
    "            b = accuracy_score(classes_test,j)\n",
    "        perform1.append(b)\n",
    "    fig, axes = plt.subplots()\n",
    "    axes.plot(perform1)\n",
    "    plt.title(\"Classification Accuracy of KNN for Different Values of k\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    plt.xlabel(\"Value of k\");\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "    return np.mean(perform1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading description pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '../data/raw/example_image/'\n",
    "segmentation_folder = '../data/raw/example_segmentation/'\n",
    "\n",
    "extra_image_folder = '../data/raw/extra_keratosis'\n",
    "extra_segmentation_folder = '../data/raw/extra_segmentation'\n",
    "\n",
    "\n",
    "extra_ground_truth = '../data/raw/ISIC-2017_Training_Part3_GroundTruth.csv'\n",
    "ground_truth = '../data/raw/example_ground_truth.csv'\n",
    "features = '../data/features/features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = os.listdir(image_folder)\n",
    "segmentation_files = os.listdir(segmentation_folder)\n",
    "\n",
    "extra_image_files = os.listdir(extra_image_folder)\n",
    "extra_segmentation_files = os.listdir(extra_segmentation_folder)\n",
    "\n",
    "extra_gt = pd.read_csv(extra_ground_truth)\n",
    "ground_truth = pd.read_csv(ground_truth)\n",
    "features = pd.read_csv(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 - Data checking and filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV files sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_null_values(ground_truth,'ground_truth')\n",
    "check_null_values(features,'features')\n",
    "check_null_values(extra_gt,'extra_ground_truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_checker_values(ground_truth,-1)\n",
    "#dataset_checker_values(features,-1)\n",
    "#dataset_checker_values(extra_gt,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no gaps in the plots, thus the value -1 (missing data) does not occur in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True in list(ground_truth.duplicated()):\n",
    "    print(\"Duplicate rows\")\n",
    "else: \n",
    "    print(\"No duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True in list(features.duplicated()):\n",
    "    print(\"Duplicate rows\")\n",
    "else:\n",
    "    print(\"No duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True in list(extra_gt.duplicated()):\n",
    "    print('Duplicate rows')\n",
    "else:\n",
    "    print('No duplicate rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ground_truth.set_index('image_id')\n",
    "features = features.set_index('id')\n",
    "extra_gt = extra_gt.set_index('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_images_paths = []\n",
    "segmentation = []\n",
    "\n",
    "# getting the image_paths\n",
    "for i in image_files[1:]:\n",
    "    image_path= os.path.join(image_folder,i)\n",
    "    if not i.endswith('superpixels.png'):\n",
    "        color_images_paths.append(image_path)\n",
    "for i in segmentation_files:\n",
    "    image_path1 = os.path.join(segmentation_folder,i)\n",
    "    segmentation.append(image_path1)\n",
    "\n",
    "# would be nice to create a function that actually checks if the tuple contains the right colored image and segemntation one\n",
    "both_images = list(zip(color_images_paths,segmentation))\n",
    "\n",
    "#splitting the images\n",
    "keratosis_images = ground_truth.index[ground_truth['seborrheic_keratosis'] == 1.0].tolist()\n",
    "melanoma_images = ground_truth.index[ground_truth['melanoma'] == 1.0].tolist()\n",
    "healthy_images = ground_truth[(ground_truth['seborrheic_keratosis'] == 0.0) & (ground_truth['melanoma'] == 0.0)]\n",
    "#print(healthy_images.index.tolist) - to get only the healthy images in a list hence the healthy_images is a df\n",
    "\n",
    "keratosis = [os.path.join(image_folder,i + '.jpg') for i in keratosis_images] #positive keratosis colour_images path\n",
    "melanoma = [os.path.join(image_folder,i + '.jpg') for i in melanoma_images] #positive melanoma colour_images path\n",
    "healthy = [os.path.join(image_folder,i + '.jpg') for i in healthy_images.index.tolist()] #healthy colour_images path\n",
    "\n",
    "k_segmentation = [os.path.join(segmentation_folder,i + '_segmentation.png') for i in keratosis_images] #positive keratosis segmentation path\n",
    "m_segmentation = [os.path.join(segmentation_folder,i + '_segmentation.png') for i in melanoma_images] #positive melanoma segmentation path\n",
    "h_segmentation = [os.path.join(segmentation_folder,i + '_segmentation.png') for i in healthy_images.index.tolist()]#healthy segmentation path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_keratosis = list(zip(keratosis,k_segmentation))\n",
    "final_melanoma = list(zip(melanoma,m_segmentation))\n",
    "final_healthy = list(zip(healthy,h_segmentation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Data - provided from ISIC 2017 challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_keratosis = [os.path.join(extra_image_folder,i) for i in extra_image_files]\n",
    "extra_segmentation = [os.path.join(extra_segmentation_folder,i) for i in extra_segmentation_files ]\n",
    "final_extra = list(zip(extra_keratosis,extra_segmentation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keratosis_all = final_keratosis + final_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_k_all = k_segmentation + extra_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Colour Analysis - Step by step example of the colour_reader function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the coloured and the segmentation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread(keratosis[1])\n",
    "mask = plt.imread(k_segmentation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic knowledge about the lession such as area and perimeter (not absolutely necessary for colour analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = np.sum(mask)\n",
    "struct_el = morphology.disk(1)\n",
    "mask_eroded = morphology.binary_erosion(mask, struct_el)\n",
    "image_perimeter = mask - mask_eroded\n",
    "perimeter = np.sum(image_perimeter)\n",
    "plt.imshow(image_perimeter,cmap = 'cool') # really small but visible with cool cmap\n",
    "#print(' The area is -> ',area,'\\\\n','The perimeter is -> ',perimeter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the lession and displaying it over the segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = im.copy()\n",
    "im1[mask==0] = 0\n",
    "new_arr_no_0 = im1[np.where(im1!=0)]\n",
    "#cropping the image for better performance\n",
    "im1 = crop(im1)\n",
    "plt.imshow(im1) #not best crop but manageable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting every pixel's coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_coords = np.flip(np.column_stack(np.where(im1 >= 0)), axis=1)\n",
    "a_del = np.delete(xy_coords, 0, 1)\n",
    "a_del = a_del[::3][:, [0, 1]] #python dark magic and true coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting every pixel's RGB values and converting them to HEX codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.fromarray(im1)\n",
    "rgb_image = image.convert('RGB')\n",
    "rgb1 = [rgb_image.getpixel((int(i[0]),int(i[1]))) for i in a_del]\n",
    "hex_codes = [RGB2HEX(i) for i in rgb1]\n",
    "counted_colours = Counter(hex_codes)\n",
    "counted_colours.pop('#000000')\n",
    "print(len(rgb1)) #3,379,770 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(counted_colours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversion of the RGB values to hex codes is due to the fact RGB values come in tuples of three (R,G,B), therefore, for a better performance we turn them to HEX codes ( which are basically #RGB values ) and then we count their appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# really long running time, ~ 1h\n",
    "final_k = [colour_reader(i[0],i[1]) for i in Keratosis_all]\n",
    "final_h = [colour_reader(i[0],i[1]) for i in final_healthy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_len = [len(i) for i in final_k]\n",
    "h_len = [len(i) for i in final_h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing k_len and h_len for the prediction algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k_len - is the number of colours found in every picture (in every pixel of that picture) for the keratosis dataset  \n",
    "h_len - is the number of colours found in every picture (in every pixel of that picture) for the healthy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Colour Analysis - Step by step example explaining the hsv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_copy = im1.copy()\n",
    "non_black_pixels_mask = np.any(im1 != [0, 0, 0], axis=-1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the first image and then creating a mask without the black borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_pic = rgb2hsv(image_copy[non_black_pixels_mask])\n",
    "maximum = np.max(hsv_pic[:,1])\n",
    "minimum = np.min(hsv_pic[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the image from RGB values to HSV values to get the saturation and getting the difference between brightest and darkest spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_hsv = [hsv(i[0],i[1]) for i in Keratosis_all]\n",
    "h_hsv = [hsv(i[0],i[1]) for i in final_healthy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing k_hsv and h_hsv for the predicition algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k_hsv - is the difference between the brightest and darkest points from every picture in the keratosis dataset  \n",
    "h_hsv - is the difference between the brightest and darkest points from every picture in the healthy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Symmetry analysis - Step by step example explaining the asymmetry level function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_sym = plt.imread(k_segmentation[1])\n",
    "y_nonzero, x_nonzero = np.nonzero(im_sym)\n",
    "im_sym = im_sym[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop the picture  \n",
    "Center of the shape is the center of the image  \n",
    "The borders of the shape are the borders of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = im_sym.shape\n",
    "width_cutoff = width // 2\n",
    "height_cutoff = height // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut the image in halves   \n",
    "Find the point of cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imVertical1 = im_sym[:, :width_cutoff]\n",
    "imVertical2 = im_sym[:, width_cutoff:]\n",
    "imHorizontal1 = im_sym[:height_cutoff, :]\n",
    "imHorizontal2 = im_sym[height_cutoff:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut the image vertically and horizontally in two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexerVertical = [slice(None)] * imVertical2.ndim\n",
    "indexerHorizontal = [slice(None)] * imHorizontal2.ndim\n",
    "indexerVertical[1] = slice(None, None, -1)\n",
    "indexerHorizontal[0] = slice(None, None, -1) \n",
    "imVertical2 = imVertical2[tuple(indexerVertical)]\n",
    "imHorizontal2 = imHorizontal2[tuple(indexerHorizontal)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip image  \n",
    "Interting one of the images both vertically and horizontally  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imVertical2 = imVertical2[0:imVertical1.shape[0], 0:imVertical1.shape[1]]\n",
    "imHorizontal2 = imHorizontal2[0:imHorizontal1.shape[0], 0:imHorizontal1.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut the biggest image, if the images don't have the same shape   \n",
    "This can happen if the shape of the original shape was an odd number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bwxVertical = cv2.bitwise_xor(imVertical1,imVertical2)\n",
    "img_bwxHorizontal = cv2.bitwise_xor(imHorizontal1,imHorizontal2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areaVertical = np.sum(img_bwxVertical == 1)\n",
    "areaHorizontal = np.sum(img_bwxHorizontal == 1)\n",
    "areaMean = (areaVertical + areaHorizontal) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(areaMean / np.sum(im_sym == 1) *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The asymmetry level (AS) is calculated as a percentage of the non-zero pixels in the overlapped image over the lesion area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_sym = [asymmetry_level(i) for i in segm_k_all]\n",
    "h_sym = [asymmetry_level(i) for i in h_segmentation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing k_sym and h_sym for the prediction algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k_sym - is the asymmetry level of every segmentation picture in the keratosis segmentation dataset  \n",
    "h_sym - is the asymmetry level of every segmentation picture in the healthy segmentation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Diagnosis prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATED\n",
    "clas_k = np.array([1 for i in range(len(Keratosis_all))])\n",
    "clas_h = np.array([0 for i in range(len(healthy))])\n",
    "clas = np.array([y for x in [clas_k, clas_h] for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Color variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = np.array(k_len + h_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_train,feed_test,clas_train,clas_test = train_test_split(feed,clas,test_size = 0.6,random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_train= feed_train.reshape(-1, 1)\n",
    "clas_train= clas_train.reshape(-1, 1)\n",
    "feed_test = feed_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_knn_prediction(7,feed_train,clas_train,feed_test))\n",
    "print(clas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test(120,feed_train,clas_train,feed_test,clas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed2 = np.array([y for x in [k_hsv, h_hsv] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed2_train,feed2_test,clas_train,clas_test = train_test_split(feed2,clas,test_size = 0.6,random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed2_train= feed2_train.reshape(-1, 1)\n",
    "clas_train= clas_train.reshape(-1, 1)\n",
    "feed2_test = feed2_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_knn_prediction(6,feed2_train,clas_train,feed2_test))\n",
    "print(clas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test(120,feed2_train,clas_train,feed2_test,clas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed3 = np.array([y for x in [k_sym, h_sym] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed3_train,feed3_test,clas_train,clas_test = train_test_split(feed3,clas,test_size = 0.6,random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed3_train= feed3_train.reshape(-1, 1)\n",
    "clas_train= clas_train.reshape(-1, 1)\n",
    "feed3_test = feed3_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_knn_prediction(7,feed3_train,clas_train,feed3_test))\n",
    "print(clas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test(120,feed3_train,clas_train,feed3_test,clas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Open question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORK IN PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example_ground_truth\n",
    "#Features\n",
    "ex_ground = pd.read_csv(\"../data/raw/example_ground_truth.csv\")\n",
    "features = pd.read_csv(\"../data/features/features.csv\")\n",
    "images = (\"../data/raw/example_image/\")\n",
    "segmentations = (\"../data/raw/example_segmentation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame object\n",
    "df_exground = pd.DataFrame(ex_ground, columns =['image_id', 'melanoma', 'seborrheic_keratosis'])\n",
    "\n",
    "# Iterate over the index range from\n",
    "# 0 to max number of columns in dataframe\n",
    "for i in range(df_exground.shape[1]):\n",
    "\n",
    "    print('Column Number : ', i)\n",
    "\n",
    "    # Select column by index position using iloc[]\n",
    "    columnSeriesObj = df_exground.iloc[:, i]\n",
    "    print('Column Contents : ', columnSeriesObj.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading of data and scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Scripts/fyp2021p3_group00_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread(\"../Data/Raw/example_image/ISIC_0014310.jpg\")\n",
    "print(im.shape)\n",
    "plt.imshow(im)\n",
    "plt.imshow(im[:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    r, g, b = rgb[:, :, 0], rgb[:, :, 1], rgb[:, :, 2]\n",
    "    gray = 0.2989 * r * 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "\n",
    "grey = rgb2gray(im)\n",
    "plt.imshow(grey,  cmap = \"gray\")\n",
    "\n",
    "# Lesion is darker, and extract a mask of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(grey)\n",
    "# Will run for a minute or two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our lesion is in the smaller clusters (The darker pixels), and the greater ones must be the pixels of the skin\n",
    "im_lim = grey < 4500\n",
    "plt.imshow(im_lim, cmap = \"gray\") # We see a little noice within our lesion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holy shit some messed op edge detections\n",
    "The resized image testing here is somewhat crazy if you run it, you will get the image in gray, and an edge detection via Laplacian method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread(\"../Data/Raw/example_image/ISIC_0015445.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "test_image1 = cv2.imread(\"../Data/Raw/example_image/ISIC_0012876.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#ISIC_0012876.jpg: 130332409512 variance value with blur filter\n",
    "#ISIC_0012547.jpg: 328304917890 variance value with blur filter\n",
    "#ISIC_0014616.jpg: 254861476159 variance value with blur filter\n",
    "#ISIC_0015445.jpg: 65980525961 original variance value, 84519790131 variance value with blur filter\n",
    "\n",
    "#above images are sharp ass hell and with clear example of their blurry version\n",
    "#Images that are less than 2 billion in variance, is considered non-blurry for the above .jpg examples\n",
    "\n",
    "\n",
    "\n",
    "image_unblur = cv2.resize(test_image, (960, 540))\n",
    "imageS = cv2.resize(test_image, (460, 280))\n",
    "imageS1 = cv2.resize(test_image1, (460, 280))\n",
    "\n",
    "#blur_sharpening = cv2.GaussianBlur(imageS, (0, 0), 3); #This line makes the images very blurry\n",
    "#cv::addWeighted(frame, 1.5, image, -0.5, 0, image);\n",
    "\n",
    "\n",
    "imageB = cv2.GaussianBlur(imageS, (5,5), 0) #Biased images are blurry\n",
    "#imageS = cv2.blur(imageS, (5,5))\n",
    "laplacian_image = cv2.Laplacian(imageS, cv2.CV_64F, ksize=11)#Change the ksize to get different edge detections, only odd numbers works\n",
    "laplacian_image1 = cv2.Laplacian(imageS1, cv2.CV_64F, ksize=11)\n",
    "canny = cv2.Canny(imageS, 20, 21) #You can change the numbers of values, to where it sees something as an edge\n",
    "\n",
    "#Laplacian.var() works in such a way that it checks for defined edges, and if the image is blurry there wound be such a clear edge like line\n",
    "img_variance = cv2.Laplacian(image_unblur, cv2.CV_64F, ksize=11).var()\n",
    "img_blur = cv2.Laplacian(imageB, cv2.CV_64F, ksize=11).var()\n",
    "\n",
    "if img_variance < 80000000000:\n",
    "    print(img_variance, \"variance value is less than 80.000.000.000 milliard, the image is blurry\")\n",
    "else:\n",
    "    print(img_variance, \"variance value is above 80.000.000.000 milliard, image is not blurry\")\n",
    "\n",
    "print(img_blur, \"variance value of an image with gaussian blur filter on\")\n",
    "\n",
    "#cv2.imshow(\"Blur to sharp\", blur_sharpening)\n",
    "#cv2.imshow(\"Original image no blur\", image_unblur)\n",
    "cv2.imshow(\"Blur filter\", imageB)\n",
    "cv2.imshow(\"Laplacian\", laplacian_image)\n",
    "cv2.imshow(\"Laplacian1\", laplacian_image1)\n",
    "#cv2.imshow(\"Canny\", canny) #The Canny edge detection is kinda weird\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder images multiple ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will get all the files in a folder in onlyfiles. And then it will read them all and store them in the array images.\n",
    "onlyfiles = [f for f in os.listdir(images) if os.path.isfile(os.path.join(images, f))]\n",
    "image_s = np.empty(len(onlyfiles), dtype = object)\n",
    "for n in range(0, len(onlyfiles)):\n",
    "    image_s[n] = cv2.imread(os.path.join(images, onlyfiles[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in image_s:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_images_from_folder(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
